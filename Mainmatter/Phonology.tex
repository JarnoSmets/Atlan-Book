\section{\setcounter{section}{-1}Introduction}

A language is a system through which an individual can communicate with others, which is structured in grammar and vocabulary. Languages are usually spoken, but can also be conveyed by signs as with sign language, or with script. The definition of language is quite a contested topic. Multiple theories about the purpose of language have been proposed. One of the first definitions of languages was put forward by Ferdinand De Saussure. De Saussure saw language as self-contained, self-regulating system, in which the elements are characterised by their relationship with other elements in the system. De Saussure named his vision on linguistics ‘semiology’, but this was posthumously named structuralism by other linguists (Matthews, 2014). 

Nowadays, linguistic scholars deem the structuralist approach outdated, and favour more recent explanations. While some linguistic scholars such as Noam Chomsky and Steven Pinker see language as a biological, formal, or ‘mathematical’ system of signs that are dictated by grammatical rules to convey an utterance (Chomsky, 2002; Pinker, 1994), other scholars such as Nicholas Evans pursue the more ‘functional’ approach and see language as a system of communication that allows for the exchange of utterances (Evans & Levinson, 2009). One other view sees language primarily and purely as a ‘tool’ that can be used for humans to undertake linguistic behaviour, in that language is solely a means of producing and understanding utterances that evolved over the course of human history (Fitch et al., 2005). 

Note that these definitions more or less convey the same meaning: “a system through which an individual can communicate”. The difference between these views is not so much what language is for, but what it emphasises. They are not mutually exclusive to a certain degree. Nonetheless, contemporary scholars predominantly adopt Chomsky's biological approach. However, even this view has been contested, on the grounds that neuroscientific studies have found neither biological nor neurologic evidence for the existence of Chomsky’s theory on the application of WH-questions, i.e., what, where, when, who(m/se), why, which, and how (Kluender & Kutas, 1993). 

English is still the most spoken language of academia worldwide, and the \textit{lingua franca} of the western world (Mauranen, 2003). It has not, however, gained this position because it is easy to speak or learn. Pronunciation of English vowels, for example, is unlike its graphemic notation, due to phonological shifts of vowels after the standardisation of English spelling in the 15th and 16th centuries (Denham & Lobeck, 2007). English did not gain its position because of the purported absence of cultural influence of English, as stated by Knapp and Meierkord (2002). English fulfils the need of a global lingua franca, as it has spread to large areas of the world due to various factors. These include the adoption of the Latin script worldwide, the invention of the internet and its first widespread use in the United States of America. 

The development of the American research university and subsequent adoption of English as \textit{the} academic language have also been of tremendous importance its widespread use. However, there exist more sinister factors as well, such as widespread colonization brought about by the British, American cultural hegemony, and the spread of Christianity through western missionaries (Ariza & Navarro, 2006). The use of English in academic language has long been postulated by some to be ‘neutral’, i.e., free of cultural influences (House, 2003). However, as of late this claim has been challenged. Scholars such as Pölzl and Seidlhofer (2006) and Knapp and Meierkord (2002) have claimed that English is ‘imperialistic’ by definition due to the use of English by colonists. These colonists subsequently decreed that English would be the sole language to be spoken in countries which do not have English as its endogenous language, and as such was seen as a form of oppression (Macedo & Bartolomé, 2014). Other scholars have presumed that English can be ‘neutral’ to a certain degree, and that it is up to the speaker of a language to give partiality to one’s words and actions (Norton, 1997). If this view is mirrored against the notion of the impartiality of language and that language and culture are interwoven to their very core as famously articulated by Kramsch (2014), it is possible to surmise that any language that has evolved naturally in humans through use and repetition without conscious planning or premeditation is intrinsically biased, due to the fact that culture and language are inherently linked (Lyons, 1991). 

Atlan is designed to be an auxiliary constructed language, a language that is created with the purpose of facilitating communication between people who have different native languages. This decision has been made because we are of the opinion that a language that is used in academic context should be neutral. This does not imply that the language shall solely be used for academic purposes, nor does it mean that it should replace other languages. 

With the creation of the language, multiple goals have been kept in mind. The primary purpose in the creation of a language is to be as culturally neutral as possible, so that no group of people will be especially favoured or disfavoured when learning the language with regards to the similarity to their own. Creating a language from scratch can procure this cornerstone. 

Another main goal is that the language should both be easy to speak and understand. The notion of unambiguity is another tenet, with the goal of reducing confusion or misinterpretation within communication as much as possible. This means being as sparse as possible, with different elements of the language, where simplicity is key, and complexity should arise from the combination of the basic elements. This is, of course, of utmost importance in phonology and morphology. If a differing consonant is used, it would change the entirety of the word. The same applies to morphology, where the distinction needs to be made between who the actor and who the recipient is. 

This paper will serve as an overview regarding the phonological and morphological considerations that have been made for the language. In the first section of this paper, I will elaborate on the neurology concerning speech and language. The second section will cover the choices that have been made regarding the phonology for consonants, vowels, and prosody. Finally, I will close this paper by summarising what has been stated, and giving some concluding remarks.



\section{The Neurologic Basis of Language}
Neurolinguistics is the study of how the brain produces, comprehends, and acquires language. 
It combines both the framework of humanities, namely the language aspect, with a neuroscience approach. The two traditional brain areas that are correlated with the production and comprehension of language and speech with respectively Broca’s area in the frontal lobe, and Wernicke’s area in the temporal lobe (Geschwind, 1972), which are connected through the \textit{fasciculus arcuatus} (Bernal & Altman, 2010). These areas are not bilaterally localized, and solely exist in the left cerebral hemisphere. 

The production of speech occurs according to three main principles: conceptualization, formulation, and articulation. In the first stage, conceptualization, an individual with the intention to create speech links the desired concept to the particular spoken words. This preverbal message contains the desired to-be conveyed thoughts to be expressed. The second stage is formulation, in which the linguistic form for the desired message is formulated. Here, knowledge of grammar, phonology, and phonetics is applied to the preverbal message. The third stage is the articulation of the message, in which motor functions are activated to produce the utterance. The perception of language or speech begins at the level of the sound signal and the process of audition. Subsequently, speech sounds are further processed in order to gain information regarding acoustic cues and phonetics. This information can then be used for processes that are considered to be ‘higher-level’ language processes, such as word recognition (Levelt, 1999). These produced sounds are then further processed in the auditory cortex of the brain. 

Research has indicated that the auditory cortex processes voiceless and voiced phonemes differently in ferrets, which have similar structures in the processing of auditive information when compared to humans (Mesgarani et al., 2008). Phonemes are, put very simply, sounds, or the smallest units of speech. Phonemes are usually divided into consonants and vowels (Yallop & Fletcher, 2007). Consonants are created by constricting the airflow in the vocal tract when air is forced out of the lungs, and is mostly done by the tongue. Some consonants can also be created by, among others, the nose and vocal tract. Voiced consonants are consonants that incorporate the vibration of the vocal cords when the articulation of the letter occurs. Some examples of voiced consonants are the /b/, /d/, and /g/. Voiceless consonants on the other hand do not make use of the vocal cords. Examples of voiceless include /p/, /t/, and /k/. Some languages, such as Arabic, do not have the voiceless bilabial plosive /p/ in their phonological inventory (Al-Ani, 1970). When a speaker of Arabic wants to say the word ‘pizza’, they would pronounce it as ‘bizza’, for the voiced bilabial plosive /b/ is used instead of the /p/. If an Italian on holiday in an Arabic-speaking country would order a pizza, pronouncing the word with the voiceless bilabial plosive /p/, a monolingual speaker of Arabic would not have any hindrances whatsoever with the comprehension of the utterance (Versteegh, 2014). This can be linked to another research by Liégeois-Chauvel et al. (1999) on the inquiry of the perception of voiced and voiceless phonemes. In this research, a speaker produced voiceless and voiced phonemes, with the following vowel being /a/ (/pa/, /ta/, /ka/ for voiceless, and /ba/, /da/, /ga/ for voiced) in a random order. Neurologic tests were carried out usinga tool called ‘electroencephalography’ (EEG). An EEG maps where in the brain electrical pulses occur, i.e., where and which areas of the brain are activated when an individual is exposed to stimuli. The EEG has shown that the auditory cortex is able to process syllables with voiced consonants from syllables with voiceless consonants in the left hemisphere, however, the right hemisphere was not able to make this distinction and solely processed acoustic stimuli. Furthermore, the auditory cortex was not able to differentiate syllables with voiced consonants and voiceless consonants. The results from the EEG showed no discernible differences between syllables with voiced and voiceless consonants. However, a differential coding of voiced and voiceless syllables is preserved. This would still mean that an individual is able to distinguish these phonemes (Liégeois-Chauvel et al., 1999). :


\Section{The Sound of Atlan}{Niek Elsinga and Stijn Janssens}


